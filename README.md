# Rockwell AI Governance Prototype
Teaching Gen AI how to be a Team Member
ğŸ¯ Overview
This project establishes a Governance & Safety Framework for integrating Large Language Models (LLMs), specifically GitHub Copilot, into industrial software development environments. The goal is to transform AI from a generic code generator into a reliable Junior Team Member that adheres to Rockwell Automationâ€™s safety, architectural, and documentation standards.
ğŸ›  Features
â€¢ Deterministic AI Guardrails: System-level instructions that enforce strict coding patterns.
â€¢ Automated Safety Validation: Integration with pytest to catch logic errors that could impact physical hardware.
â€¢ Hallucination Mitigation: Grounding AI responses in specific industrial contexts to prevent the use of non-existent libraries.
â€¢ Fail-Safe Logic Design: Patterns that ensure systems default to a secure state upon sensor or communication failure.
ğŸ— Project Structure
rockwell-ai-governance/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md  <-- The "Rules of Governance"
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sensor_reader.py         <-- Industrial sensor simulation
â”‚   â””â”€â”€ safety_protocols.py      <-- Fail-safe logic implementation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_sensor.py           <-- Unit tests for boundary validation
â”‚   â””â”€â”€ stress_test.py           <-- AI-generated code stress testing
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸš¦ Governance & Safety Rules
The framework enforces the following standards through .github/copilot-instructions.md:
1. Type Safety: All Python functions must include Type Hints.
2. Documentation: Strict adherence to Google-Style Docstrings.
3. Boundary Validation: Every input must be sanitized against predefined industrial ranges (e.g., SENS- ID prefix).
4. Defensive Programming: Mandatory try-except blocks for all hardware-simulating functions.

ğŸ§ª Testing & Validation
The project uses pytest to ensure that even if the AI suggests a solution, it passes our safety thresholds.
Safety Boundary Test
Validates that telemetry data never exceeds critical physical limits:


def test_sensor_safety_boundary():
    result = read_industrial_sensor("SENS-01")
    if result is not None:
        assert result <= 100.0  # Critical Safety Limit

How to run tests:

python -m pytest tests/test_sensor.py

ğŸ“ˆ Key Findings (The "101.4Â°C" Case)
During development, a stress test identified a Critical Security Violation where the AI-generated telemetry returned 101.4Â°C.
â€¢ Result: The test suite successfully blocked the execution.
â€¢ Lesson: This proves that Automated Guardrails are essential to prevent AI hallucinations from affecting industrial safety.

ğŸš€ Future Roadmap
â€¢ RAG Integration: Connecting the framework to official Rockwell manuals (PDFs/Wikis).
â€¢ Multi-language Support: Expanding governance rules to C++ and Go.
â€¢ Automated PR Reviewer: Using AI to flag code that violates safety conventions.
Author: Oskar Vanegas
Role: AI Governance & Software Safety Intern (Candidate)
Company: Rockwell Automation Internship Program FY26

